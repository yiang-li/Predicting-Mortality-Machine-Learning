{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   z_livgrad  z_ix011rec  z_ax341re  z_ax342re  z_ix001rer  z_gx360re  \\\n0          1          32        1.0        2.0           4          1   \n1          1          27        2.0        2.0           4          2   \n2          1          29        1.0        1.0           5          2   \n3          1          28        NaN        NaN           5          2   \n4          1          26        NaN        NaN           4          1   \n\n   z_ix013rec  z_gu025re  z_brdxdy  z_gb103red  ...  z_gc042re  z_sexrsp  \\\n0           2          1        38          19  ...          1         1   \n1           2          1        39          20  ...          3         1   \n2           2          1        39          12  ...          3         1   \n3           1          1        38          14  ...          3         1   \n4           2          1        41          12  ...          1         1   \n\n   z_ie020re  z_il003rer  z_gd103kd  z_id014cre  z_iz106rer  z_in504rer  \\\n0          1           3          2           2           1           5   \n1          1           4          2           2           2           6   \n2          1           3          1           2           2           1   \n3          1           4          2           2           2           4   \n4          1          -3          2           2           2           3   \n\n   z_iz023rer  z_iv032re  \n0           2          1  \n1           6          2  \n2           2          1  \n3           1          2  \n4          -3         -3  \n\n[5 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>z_livgrad</th>\n      <th>z_ix011rec</th>\n      <th>z_ax341re</th>\n      <th>z_ax342re</th>\n      <th>z_ix001rer</th>\n      <th>z_gx360re</th>\n      <th>z_ix013rec</th>\n      <th>z_gu025re</th>\n      <th>z_brdxdy</th>\n      <th>z_gb103red</th>\n      <th>...</th>\n      <th>z_gc042re</th>\n      <th>z_sexrsp</th>\n      <th>z_ie020re</th>\n      <th>z_il003rer</th>\n      <th>z_gd103kd</th>\n      <th>z_id014cre</th>\n      <th>z_iz106rer</th>\n      <th>z_in504rer</th>\n      <th>z_iz023rer</th>\n      <th>z_iv032re</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>32</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>38</td>\n      <td>19</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>27</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>39</td>\n      <td>20</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>29</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>5</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>39</td>\n      <td>12</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>28</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>38</td>\n      <td>14</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>26</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>41</td>\n      <td>12</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>-3</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>-3</td>\n      <td>-3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data\n",
    "wls_raw = pd.read_csv('wls.csv', low_memory=False)\n",
    "# Select the variables of interest\n",
    "wls_select = wls_raw[['z_livgrad', 'z_ix011rec', 'z_ax341re', 'z_ax342re',\n",
    "                      'z_ix001rer', 'z_gx360re', 'z_ix013rec', 'z_gu025re',\n",
    "                      'z_brdxdy', 'z_gb103red', 'z_gp260hec', 'z_gc042re', 'z_sexrsp',\n",
    "                      'z_ie020re', 'z_il003rer', 'z_gd103kd', 'z_id014cre',\n",
    "                      'z_iz106rer', 'z_in504rer', 'z_iz023rer', 'z_iv032re'\n",
    "                      ]]\n",
    "# Show the first five rows\n",
    "wls_select.head(n=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 0 missing value in the target: disposition status\n",
      "There are 2384 positive cases and 7565 negative cases in target\n"
     ]
    }
   ],
   "source": [
    "# Copy the data for preprocessing\n",
    "wls = wls_select.copy()\n",
    "# Check the missing values in the target\n",
    "print(\"There is {} missing value in the target: disposition status\".format(wls_select['z_livgrad'].isnull().sum()))\n",
    "# Recode the target for easier interpretation\n",
    "wls['deceased'] = np.where(wls['z_livgrad'] == 1, \"Alive\", \"Deceased\")\n",
    "wls = wls.drop('z_livgrad', axis=1)\n",
    "# Show the balance of the target\n",
    "print(\"There are {} positive cases and {} negative cases in target\".format(wls['deceased'].value_counts()[1],\n",
    "                                                                           wls['deceased'].value_counts()[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed 1605 respondents with missing ordinal variables\n"
     ]
    },
    {
     "data": {
      "text/plain": "               BMI  Self-Rated Health          Age  Years of Education  \\\ncount  9949.000000        9949.000000  9949.000000         9949.000000   \nmean     27.874934           4.006127    39.381785           13.774586   \nstd       4.849958           0.675229     4.236784            2.403011   \nmin      19.000000           1.000000    18.000000            0.000000   \n25%      25.000000           4.000000    38.000000           12.000000   \n50%      27.000000           4.000000    39.000000           12.000000   \n75%      30.000000           4.000000    39.000000           16.000000   \nmax      45.000000           5.000000    60.000000           21.000000   \n\n       Household Income  Religion Importance  Social with Relatives  \\\ncount       9949.000000          9949.000000            9949.000000   \nmean       64790.547838             3.558197               1.323093   \nstd        79392.196592             1.085866               0.477515   \nmin            0.000000             1.000000               1.000000   \n25%        22272.000000             3.000000               1.000000   \n50%        46000.000000             4.000000               1.000000   \n75%        78400.000000             4.000000               2.000000   \nmax       710000.000000             5.000000               3.000000   \n\n       Volunteering  Social with Friends  \ncount   9949.000000          9949.000000  \nmean       3.830626             3.548445  \nstd        1.689978             3.738867  \nmin        1.000000             0.000000  \n25%        3.000000             1.000000  \n50%        4.000000             3.000000  \n75%        5.000000             4.000000  \nmax        7.000000            28.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BMI</th>\n      <th>Self-Rated Health</th>\n      <th>Age</th>\n      <th>Years of Education</th>\n      <th>Household Income</th>\n      <th>Religion Importance</th>\n      <th>Social with Relatives</th>\n      <th>Volunteering</th>\n      <th>Social with Friends</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>9949.000000</td>\n      <td>9949.000000</td>\n      <td>9949.000000</td>\n      <td>9949.000000</td>\n      <td>9949.000000</td>\n      <td>9949.000000</td>\n      <td>9949.000000</td>\n      <td>9949.000000</td>\n      <td>9949.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>27.874934</td>\n      <td>4.006127</td>\n      <td>39.381785</td>\n      <td>13.774586</td>\n      <td>64790.547838</td>\n      <td>3.558197</td>\n      <td>1.323093</td>\n      <td>3.830626</td>\n      <td>3.548445</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>4.849958</td>\n      <td>0.675229</td>\n      <td>4.236784</td>\n      <td>2.403011</td>\n      <td>79392.196592</td>\n      <td>1.085866</td>\n      <td>0.477515</td>\n      <td>1.689978</td>\n      <td>3.738867</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>19.000000</td>\n      <td>1.000000</td>\n      <td>18.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>25.000000</td>\n      <td>4.000000</td>\n      <td>38.000000</td>\n      <td>12.000000</td>\n      <td>22272.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>27.000000</td>\n      <td>4.000000</td>\n      <td>39.000000</td>\n      <td>12.000000</td>\n      <td>46000.000000</td>\n      <td>4.000000</td>\n      <td>1.000000</td>\n      <td>4.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>30.000000</td>\n      <td>4.000000</td>\n      <td>39.000000</td>\n      <td>16.000000</td>\n      <td>78400.000000</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>5.000000</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>45.000000</td>\n      <td>5.000000</td>\n      <td>60.000000</td>\n      <td>21.000000</td>\n      <td>710000.000000</td>\n      <td>5.000000</td>\n      <td>3.000000</td>\n      <td>7.000000</td>\n      <td>28.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess continuous/ordinal variables\n",
    "# Create a list of continuous/ordinal variables\n",
    "con_col = ['z_ix011rec', 'z_ix001rer', 'z_brdxdy', 'z_gb103red', 'z_gp260hec',\n",
    "           'z_il003rer', 'z_iz106rer', 'z_in504rer', 'z_iz023rer']\n",
    "# Create a new dataframe with only continuous/ordinal variables\n",
    "wls_ord = wls[wls[con_col].notnull()].copy()[con_col]\n",
    "# Set values of missing ordinal variables initially coded as negative to nan\n",
    "wls_ord[wls_ord < 0] = np.nan\n",
    "# Check the number of missing values in original ordinal variables\n",
    "wls_ord_na = wls_ord.dropna()\n",
    "print(\"Fixed {} respondents with missing ordinal variables\".format(len(wls_ord) - len(wls_ord_na)))\n",
    "# Fill the missing values with the mean of the variable\n",
    "wls_ord.fillna(wls_ord.mean(), inplace=True)\n",
    "# Convert the continuous variables from text to numeric variables\n",
    "for col in con_col:\n",
    "    wls_ord[col] = pd.to_numeric(wls_ord[col])\n",
    "# Name the columns\n",
    "wls_ord.columns = ['BMI', 'Self-Rated Health', 'Age', 'Years of Education',\n",
    "                   'Household Income', 'Religion Importance',\n",
    "                   'Social with Relatives', 'Volunteering',\n",
    "                   'Social with Friends']\n",
    "# Get the summary statistics of the ordinal variables\n",
    "wls_ord.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "While preprocessing the data, I found that `z_ax341re` and `z_ax342re` has many missing values. This is because the questionnaire was only sent to a portion of the respondents. Because based on the previous analysis on NSHAP, I believe these two features are important, I decided to keep these two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed missing on hypertension 4466\n",
      "Fixed missing on diabetes 4458\n"
     ]
    },
    {
     "data": {
      "text/plain": "     Hypertension Diabetes Arthritis Smoking Status Drunk Alcohol  \\\n0             Yes       No       Yes             No           Yes   \n1              No       No        No             No           Yes   \n2             Yes      Yes        No             No           Yes   \n3              No       No        No            Yes           Yes   \n4              No       No       Yes             No           Yes   \n...           ...      ...       ...            ...           ...   \n9944           No       No        No             No           Yes   \n9945           No       No        No             No           Yes   \n9946          Yes       No        No             No           Yes   \n9947          Yes      Yes        No             No           Yes   \n9948          Yes       No        No             No           Yes   \n\n     Martial Status Children Coresidence Grandchildren Coresidence  \\\n0               Yes                   No                        No   \n1                No                   No                        No   \n2                No                  Yes                        No   \n3                No                   No                        No   \n4               Yes                   No                        No   \n...             ...                  ...                       ...   \n9944            Yes                   No                        No   \n9945             No                   No                        No   \n9946             No                   No                        No   \n9947            Yes                   No                        No   \n9948            Yes                  Yes                       Yes   \n\n     Functional Limitation     Sex   Race  \n0                      Yes    Male  White  \n1                       No    Male  White  \n2                      Yes    Male  White  \n3                       No    Male  White  \n4                       No    Male  White  \n...                    ...     ...    ...  \n9944                   Yes    Male  White  \n9945                    No    Male  White  \n9946                    No  Female  White  \n9947                    No    Male  White  \n9948                    No  Female  White  \n\n[9949 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Hypertension</th>\n      <th>Diabetes</th>\n      <th>Arthritis</th>\n      <th>Smoking Status</th>\n      <th>Drunk Alcohol</th>\n      <th>Martial Status</th>\n      <th>Children Coresidence</th>\n      <th>Grandchildren Coresidence</th>\n      <th>Functional Limitation</th>\n      <th>Sex</th>\n      <th>Race</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9944</th>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>9945</th>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>9946</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>9947</th>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>9948</th>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>White</td>\n    </tr>\n  </tbody>\n</table>\n<p>9949 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess categorical/binary variables\n",
    "cat_col = ['z_ax341re', 'z_ax342re', 'z_gx360re', 'z_ix013rec', 'z_gu025re',\n",
    "           'z_gc042re', 'z_gd103kd', 'z_id014cre', 'z_iv032re',\n",
    "           'z_sexrsp', 'z_ie020re', ]\n",
    "# Create a new dataframe with only categorical/binary variables\n",
    "wls_cat = wls[wls[cat_col].notnull()].copy()[cat_col]\n",
    "# Set values of missing categorical variables initially coded as negative to nan\n",
    "wls_cat[wls_cat < 0] = np.nan\n",
    "# Check the number of missing values in original categorical variables\n",
    "print(\"Fixed missing on hypertension\", wls_cat['z_ax341re'].isnull().sum())\n",
    "print(\"Fixed missing on diabetes\", wls_cat['z_ax342re'].isnull().sum())\n",
    "# Fill the missing values with the mode of the variable\n",
    "wls_cat.fillna(wls_cat.mode().iloc[0], inplace=True)\n",
    "# Set values of missing categorical variables initially coded as negative to nan\n",
    "for col in cat_col[:9]:\n",
    "    wls_cat[col] = np.where(wls_cat[col] == 1, \"Yes\", \"No\")\n",
    "    wls_cat[col] = wls_cat[col].astype('category')\n",
    "wls_cat['z_sexrsp'] = np.where(wls_cat['z_sexrsp'] == 1, \"Male\", \"Female\")\n",
    "wls_cat['z_ie020re'] = np.where(wls_cat['z_ie020re'] == 1, \"White\", \"Non-White\")\n",
    "# Name the columns\n",
    "wls_cat.columns = ['Hypertension', 'Diabetes', 'Arthritis', 'Smoking Status',\n",
    "                   'Drunk Alcohol', 'Martial Status',\n",
    "                   'Children Coresidence', 'Grandchildren Coresidence',\n",
    "                   'Functional Limitation',\n",
    "                   'Sex', 'Race']\n",
    "wls_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "    deceased   BMI  Self-Rated Health   Age  Years of Education  \\\n0      Alive  32.0                4.0  38.0                19.0   \n1      Alive  27.0                4.0  39.0                20.0   \n2      Alive  29.0                5.0  39.0                12.0   \n3      Alive  28.0                5.0  38.0                14.0   \n4      Alive  26.0                4.0  41.0                12.0   \n..       ...   ...                ...   ...                 ...   \n95     Alive  31.0                4.0  53.0                12.0   \n96  Deceased  38.0                4.0  38.0                12.0   \n97  Deceased  26.0                4.0  39.0                17.0   \n98     Alive  22.0                4.0  31.0                18.0   \n99     Alive  25.0                4.0  37.0                12.0   \n\n    Household Income  Religion Importance  Social with Relatives  \\\n0            81784.0             3.000000                    1.0   \n1            87000.0             4.000000                    2.0   \n2            85354.0             3.000000                    2.0   \n3           336604.0             4.000000                    2.0   \n4            82800.0             3.558197                    2.0   \n..               ...                  ...                    ...   \n95           80000.0             2.000000                    1.0   \n96           11904.0             3.000000                    1.0   \n97           71400.0             4.000000                    2.0   \n98               0.0             4.000000                    1.0   \n99           48852.0             4.000000                    1.0   \n\n    Volunteering  Social with Friends  ... Diabetes Arthritis Smoking Status  \\\n0            5.0             2.000000  ...       No       Yes             No   \n1            6.0             6.000000  ...       No        No             No   \n2            1.0             2.000000  ...      Yes        No             No   \n3            4.0             1.000000  ...       No        No            Yes   \n4            3.0             3.548445  ...       No       Yes             No   \n..           ...                  ...  ...      ...       ...            ...   \n95           6.0             0.000000  ...       No        No            Yes   \n96           3.0             3.000000  ...       No        No             No   \n97           7.0            12.000000  ...       No       Yes             No   \n98           7.0            28.000000  ...       No        No             No   \n99           1.0             0.000000  ...      Yes       Yes             No   \n\n   Drunk Alcohol Martial Status Children Coresidence  \\\n0            Yes            Yes                   No   \n1            Yes             No                   No   \n2            Yes             No                  Yes   \n3            Yes             No                   No   \n4            Yes            Yes                   No   \n..           ...            ...                  ...   \n95           Yes             No                   No   \n96           Yes            Yes                   No   \n97           Yes            Yes                   No   \n98           Yes            Yes                   No   \n99           Yes            Yes                   No   \n\n   Grandchildren Coresidence Functional Limitation     Sex   Race  \n0                         No                   Yes    Male  White  \n1                         No                    No    Male  White  \n2                         No                   Yes    Male  White  \n3                         No                    No    Male  White  \n4                         No                    No    Male  White  \n..                       ...                   ...     ...    ...  \n95                        No                    No  Female  White  \n96                        No                    No  Female  White  \n97                        No                    No  Female  White  \n98                        No                    No  Female  White  \n99                        No                    No    Male  White  \n\n[100 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>deceased</th>\n      <th>BMI</th>\n      <th>Self-Rated Health</th>\n      <th>Age</th>\n      <th>Years of Education</th>\n      <th>Household Income</th>\n      <th>Religion Importance</th>\n      <th>Social with Relatives</th>\n      <th>Volunteering</th>\n      <th>Social with Friends</th>\n      <th>...</th>\n      <th>Diabetes</th>\n      <th>Arthritis</th>\n      <th>Smoking Status</th>\n      <th>Drunk Alcohol</th>\n      <th>Martial Status</th>\n      <th>Children Coresidence</th>\n      <th>Grandchildren Coresidence</th>\n      <th>Functional Limitation</th>\n      <th>Sex</th>\n      <th>Race</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alive</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>38.0</td>\n      <td>19.0</td>\n      <td>81784.0</td>\n      <td>3.000000</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>2.000000</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alive</td>\n      <td>27.0</td>\n      <td>4.0</td>\n      <td>39.0</td>\n      <td>20.0</td>\n      <td>87000.0</td>\n      <td>4.000000</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>6.000000</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alive</td>\n      <td>29.0</td>\n      <td>5.0</td>\n      <td>39.0</td>\n      <td>12.0</td>\n      <td>85354.0</td>\n      <td>3.000000</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>2.000000</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alive</td>\n      <td>28.0</td>\n      <td>5.0</td>\n      <td>38.0</td>\n      <td>14.0</td>\n      <td>336604.0</td>\n      <td>4.000000</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Alive</td>\n      <td>26.0</td>\n      <td>4.0</td>\n      <td>41.0</td>\n      <td>12.0</td>\n      <td>82800.0</td>\n      <td>3.558197</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.548445</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>Alive</td>\n      <td>31.0</td>\n      <td>4.0</td>\n      <td>53.0</td>\n      <td>12.0</td>\n      <td>80000.0</td>\n      <td>2.000000</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>96</th>\n      <td>Deceased</td>\n      <td>38.0</td>\n      <td>4.0</td>\n      <td>38.0</td>\n      <td>12.0</td>\n      <td>11904.0</td>\n      <td>3.000000</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>97</th>\n      <td>Deceased</td>\n      <td>26.0</td>\n      <td>4.0</td>\n      <td>39.0</td>\n      <td>17.0</td>\n      <td>71400.0</td>\n      <td>4.000000</td>\n      <td>2.0</td>\n      <td>7.0</td>\n      <td>12.000000</td>\n      <td>...</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>98</th>\n      <td>Alive</td>\n      <td>22.0</td>\n      <td>4.0</td>\n      <td>31.0</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>28.000000</td>\n      <td>...</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Female</td>\n      <td>White</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>Alive</td>\n      <td>25.0</td>\n      <td>4.0</td>\n      <td>37.0</td>\n      <td>12.0</td>\n      <td>48852.0</td>\n      <td>4.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>Yes</td>\n      <td>Yes</td>\n      <td>No</td>\n      <td>No</td>\n      <td>No</td>\n      <td>Male</td>\n      <td>White</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wls_clean = pd.concat([wls['deceased'], wls_ord, wls_cat], axis=1)\n",
    "wls_clean.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "      deceased        BMI  Self-Rated Health   Age  Years of Education  \\\n0            0  32.000000                4.0  38.0                19.0   \n1            0  27.000000                4.0  39.0                20.0   \n2            0  29.000000                5.0  39.0                12.0   \n3            0  28.000000                5.0  38.0                14.0   \n4            0  26.000000                4.0  41.0                12.0   \n...        ...        ...                ...   ...                 ...   \n9944         0  31.000000                4.0  44.0                16.0   \n9945         1  27.000000                4.0  39.0                12.0   \n9946         0  27.874934                4.0  43.0                12.0   \n9947         0  31.000000                4.0  38.0                12.0   \n9948         0  25.000000                5.0  39.0                12.0   \n\n      Household Income  Religion Importance  Social with Relatives  \\\n0              81784.0             3.000000               1.000000   \n1              87000.0             4.000000               2.000000   \n2              85354.0             3.000000               2.000000   \n3             336604.0             4.000000               2.000000   \n4              82800.0             3.558197               2.000000   \n...                ...                  ...                    ...   \n9944           94200.0             3.000000               1.000000   \n9945           41500.0             5.000000               1.000000   \n9946               0.0             1.000000               1.000000   \n9947           52700.0             5.000000               1.323093   \n9948           48972.0             4.000000               2.000000   \n\n      Volunteering  Social with Friends  ...  Diabetes  Arthritis  \\\n0              5.0             2.000000  ...         0          1   \n1              6.0             6.000000  ...         0          0   \n2              1.0             2.000000  ...         1          0   \n3              4.0             1.000000  ...         0          0   \n4              3.0             3.548445  ...         0          1   \n...            ...                  ...  ...       ...        ...   \n9944           6.0             5.000000  ...         0          0   \n9945           1.0             1.000000  ...         0          0   \n9946           6.0             3.000000  ...         0          0   \n9947           3.0             2.000000  ...         1          0   \n9948           5.0             4.000000  ...         0          0   \n\n      Smoking Status  Drunk Alcohol  Martial Status  Children Coresidence  \\\n0                  0              1               1                     0   \n1                  0              1               0                     0   \n2                  0              1               0                     1   \n3                  1              1               0                     0   \n4                  0              1               1                     0   \n...              ...            ...             ...                   ...   \n9944               0              1               1                     0   \n9945               0              1               0                     0   \n9946               0              1               0                     0   \n9947               0              1               1                     0   \n9948               0              1               1                     1   \n\n      Grandchildren Coresidence  Functional Limitation  Sex  Race  \n0                             0                      1    1     1  \n1                             0                      0    1     1  \n2                             0                      1    1     1  \n3                             0                      0    1     1  \n4                             0                      0    1     1  \n...                         ...                    ...  ...   ...  \n9944                          0                      1    1     1  \n9945                          0                      0    1     1  \n9946                          0                      0    0     1  \n9947                          0                      0    1     1  \n9948                          1                      0    0     1  \n\n[9949 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>deceased</th>\n      <th>BMI</th>\n      <th>Self-Rated Health</th>\n      <th>Age</th>\n      <th>Years of Education</th>\n      <th>Household Income</th>\n      <th>Religion Importance</th>\n      <th>Social with Relatives</th>\n      <th>Volunteering</th>\n      <th>Social with Friends</th>\n      <th>...</th>\n      <th>Diabetes</th>\n      <th>Arthritis</th>\n      <th>Smoking Status</th>\n      <th>Drunk Alcohol</th>\n      <th>Martial Status</th>\n      <th>Children Coresidence</th>\n      <th>Grandchildren Coresidence</th>\n      <th>Functional Limitation</th>\n      <th>Sex</th>\n      <th>Race</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>32.000000</td>\n      <td>4.0</td>\n      <td>38.0</td>\n      <td>19.0</td>\n      <td>81784.0</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>5.0</td>\n      <td>2.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>27.000000</td>\n      <td>4.0</td>\n      <td>39.0</td>\n      <td>20.0</td>\n      <td>87000.0</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>6.0</td>\n      <td>6.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>29.000000</td>\n      <td>5.0</td>\n      <td>39.0</td>\n      <td>12.0</td>\n      <td>85354.0</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>1.0</td>\n      <td>2.000000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>28.000000</td>\n      <td>5.0</td>\n      <td>38.0</td>\n      <td>14.0</td>\n      <td>336604.0</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>4.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>26.000000</td>\n      <td>4.0</td>\n      <td>41.0</td>\n      <td>12.0</td>\n      <td>82800.0</td>\n      <td>3.558197</td>\n      <td>2.000000</td>\n      <td>3.0</td>\n      <td>3.548445</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9944</th>\n      <td>0</td>\n      <td>31.000000</td>\n      <td>4.0</td>\n      <td>44.0</td>\n      <td>16.0</td>\n      <td>94200.0</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>6.0</td>\n      <td>5.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9945</th>\n      <td>1</td>\n      <td>27.000000</td>\n      <td>4.0</td>\n      <td>39.0</td>\n      <td>12.0</td>\n      <td>41500.0</td>\n      <td>5.000000</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9946</th>\n      <td>0</td>\n      <td>27.874934</td>\n      <td>4.0</td>\n      <td>43.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>6.0</td>\n      <td>3.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9947</th>\n      <td>0</td>\n      <td>31.000000</td>\n      <td>4.0</td>\n      <td>38.0</td>\n      <td>12.0</td>\n      <td>52700.0</td>\n      <td>5.000000</td>\n      <td>1.323093</td>\n      <td>3.0</td>\n      <td>2.000000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9948</th>\n      <td>0</td>\n      <td>25.000000</td>\n      <td>5.0</td>\n      <td>39.0</td>\n      <td>12.0</td>\n      <td>48972.0</td>\n      <td>4.000000</td>\n      <td>2.000000</td>\n      <td>5.0</td>\n      <td>4.000000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>9949 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wls_clean['deceased'] = (wls_clean['deceased'] == 'Deceased').astype(int)\n",
    "\n",
    "wls_clean['Hypertension'] = (wls_clean['Hypertension'] == 'Yes').astype(int)\n",
    "wls_clean['Diabetes'] = (wls_clean['Diabetes'] == 'Yes').astype(int)\n",
    "wls_clean['Arthritis'] = (wls_clean['Arthritis'] == 'Yes').astype(int)\n",
    "wls_clean['Smoking Status'] = (wls_clean['Smoking Status'] == 'Yes').astype(int)\n",
    "wls_clean['Drunk Alcohol'] = (wls_clean['Drunk Alcohol'] == 'Yes').astype(int)\n",
    "wls_clean['Martial Status'] = (wls_clean['Martial Status'] == 'Yes').astype(int)\n",
    "wls_clean['Children Coresidence'] = (wls_clean['Children Coresidence'] == 'Yes').astype(int)\n",
    "wls_clean['Grandchildren Coresidence'] = (wls_clean['Grandchildren Coresidence'] == 'Yes').astype(int)\n",
    "wls_clean['Functional Limitation'] = (wls_clean['Functional Limitation'] == 'Yes').astype(int)\n",
    "\n",
    "wls_clean['Sex'] = (wls_clean['Sex'] == 'Male').astype(int)\n",
    "wls_clean['Race'] = (wls_clean['Race'] == 'White').astype(int)\n",
    "wls_clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wls_clean.to_csv('wls_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train size:  (5969, 20)\n",
      "X_test size:  (1990, 20)\n",
      "y_train size:  (5969, 1)\n",
      "y_test size:  (1990, 1)\n"
     ]
    }
   ],
   "source": [
    "wls_df = pd.read_csv('wls_clean.csv')\n",
    "\n",
    "y_df = wls_df[['deceased']]\n",
    "X_df = wls_df.drop(columns=['deceased'], inplace=False)\n",
    "X_train_v, X_test, y_train_v, y_test = train_test_split(X_df, y_df,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=seed,\n",
    "                                                        shuffle=True)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_v, y_train_v,\n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state=seed,\n",
    "                                                  shuffle=True)\n",
    "\n",
    "print(\"X_train size: \", X_train.shape)\n",
    "print(\"X_test size: \", X_test.shape)\n",
    "print(\"y_train size: \", y_train.shape)\n",
    "print(\"y_test size: \", y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "            BMI  Self-Rated Health   Age  Years of Education  \\\n6590  33.000000                3.0  39.0           12.000000   \n9722  24.000000                4.0  39.0           16.000000   \n1362  35.000000                4.0  38.0           12.000000   \n8856  40.000000                4.0  39.0           12.000000   \n1521  24.000000                3.0  37.0           13.774586   \n...         ...                ...   ...                 ...   \n5000  29.000000                4.0  29.0           12.000000   \n905   24.000000                4.0  39.0           18.000000   \n2663  26.000000                5.0  35.0           20.000000   \n5919  27.874934                4.0  36.0           15.000000   \n4530  30.000000                4.0  40.0           16.000000   \n\n      Household Income  Religion Importance  Social with Relatives  \\\n6590           38600.0             4.000000                    1.0   \n9722           14712.0             4.000000                    1.0   \n1362           26016.0             3.558197                    1.0   \n8856           51816.0             4.000000                    1.0   \n1521               0.0             4.000000                    1.0   \n...                ...                  ...                    ...   \n5000           27760.0             5.000000                    1.0   \n905            31600.0             2.000000                    2.0   \n2663          144900.0             5.000000                    1.0   \n5919           10908.0             1.000000                    1.0   \n4530            7200.0             4.000000                    1.0   \n\n      Volunteering  Social with Friends  Hypertension  Diabetes  Arthritis  \\\n6590           3.0             2.000000             0         0          1   \n9722           7.0             3.548445             0         0          0   \n1362           3.0             8.000000             1         0          0   \n8856           2.0             2.000000             0         0          1   \n1521           1.0             6.000000             0         0          0   \n...            ...                  ...           ...       ...        ...   \n5000           2.0             1.000000             0         0          1   \n905            4.0             4.000000             1         0          0   \n2663           5.0             0.000000             0         0          1   \n5919           6.0             6.000000             0         0          0   \n4530           5.0             8.000000             0         0          1   \n\n      Smoking Status  Drunk Alcohol  Martial Status  Children Coresidence  \\\n6590               0              1               0                     0   \n9722               0              0               1                     0   \n1362               0              1               1                     0   \n8856               1              1               1                     0   \n1521               0              1               1                     0   \n...              ...            ...             ...                   ...   \n5000               0              1               0                     0   \n905                0              1               1                     0   \n2663               0              0               0                     1   \n5919               0              1               0                     0   \n4530               0              1               1                     0   \n\n      Grandchildren Coresidence  Functional Limitation  Sex  Race  \n6590                          0                      0    1     1  \n9722                          0                      1    0     1  \n1362                          0                      0    0     1  \n8856                          0                      1    0     1  \n1521                          0                      0    1     1  \n...                         ...                    ...  ...   ...  \n5000                          0                      0    1     1  \n905                           0                      0    0     1  \n2663                          1                      0    1     1  \n5919                          0                      0    1     1  \n4530                          0                      0    0     1  \n\n[5969 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>BMI</th>\n      <th>Self-Rated Health</th>\n      <th>Age</th>\n      <th>Years of Education</th>\n      <th>Household Income</th>\n      <th>Religion Importance</th>\n      <th>Social with Relatives</th>\n      <th>Volunteering</th>\n      <th>Social with Friends</th>\n      <th>Hypertension</th>\n      <th>Diabetes</th>\n      <th>Arthritis</th>\n      <th>Smoking Status</th>\n      <th>Drunk Alcohol</th>\n      <th>Martial Status</th>\n      <th>Children Coresidence</th>\n      <th>Grandchildren Coresidence</th>\n      <th>Functional Limitation</th>\n      <th>Sex</th>\n      <th>Race</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6590</th>\n      <td>33.000000</td>\n      <td>3.0</td>\n      <td>39.0</td>\n      <td>12.000000</td>\n      <td>38600.0</td>\n      <td>4.000000</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9722</th>\n      <td>24.000000</td>\n      <td>4.0</td>\n      <td>39.0</td>\n      <td>16.000000</td>\n      <td>14712.0</td>\n      <td>4.000000</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>3.548445</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1362</th>\n      <td>35.000000</td>\n      <td>4.0</td>\n      <td>38.0</td>\n      <td>12.000000</td>\n      <td>26016.0</td>\n      <td>3.558197</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>8.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8856</th>\n      <td>40.000000</td>\n      <td>4.0</td>\n      <td>39.0</td>\n      <td>12.000000</td>\n      <td>51816.0</td>\n      <td>4.000000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1521</th>\n      <td>24.000000</td>\n      <td>3.0</td>\n      <td>37.0</td>\n      <td>13.774586</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>6.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5000</th>\n      <td>29.000000</td>\n      <td>4.0</td>\n      <td>29.0</td>\n      <td>12.000000</td>\n      <td>27760.0</td>\n      <td>5.000000</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>905</th>\n      <td>24.000000</td>\n      <td>4.0</td>\n      <td>39.0</td>\n      <td>18.000000</td>\n      <td>31600.0</td>\n      <td>2.000000</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>4.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2663</th>\n      <td>26.000000</td>\n      <td>5.0</td>\n      <td>35.0</td>\n      <td>20.000000</td>\n      <td>144900.0</td>\n      <td>5.000000</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5919</th>\n      <td>27.874934</td>\n      <td>4.0</td>\n      <td>36.0</td>\n      <td>15.000000</td>\n      <td>10908.0</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>6.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4530</th>\n      <td>30.000000</td>\n      <td>4.0</td>\n      <td>40.0</td>\n      <td>16.000000</td>\n      <td>7200.0</td>\n      <td>4.000000</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>8.000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5969 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Con_ftr = ['BMI', 'Self-Rated Health', 'Age', 'Years of Education', 'Household Income', 'Religion Importance',\n",
    "           'Social with Relatives']\n",
    "Cat_ftr = ['Hypertension', 'Diabetes', 'Arthritis', 'Smoking Status', 'Drunk Alcohol', 'Martial Status',\n",
    "           'Children Coresidence', 'Grandchildren Coresidence', 'Functional Limitation', 'Sex', 'Race']\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train distribution: \n",
      " 0    4520\n",
      "1    1449\n",
      "Name: deceased, dtype: int64\n",
      "y_test distribution: \n",
      " 0    1520\n",
      "1     470\n",
      "Name: deceased, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"y_train distribution: \\n\", y_train['deceased'].value_counts())\n",
    "print(\"y_test distribution: \\n\", y_test['deceased'].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 3, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.757 (+/-0.001) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "0.757 (+/-0.001) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "0.757 (+/-0.001) for {'C': 0.001, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 0.001, 'penalty': 'l2'}\n",
      "0.759 (+/-0.004) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.775 (+/-0.008) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.777 (+/-0.008) for {'C': 1.0, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 1.0, 'penalty': 'l2'}\n",
      "0.778 (+/-0.009) for {'C': 2, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 2, 'penalty': 'l2'}\n",
      "0.780 (+/-0.013) for {'C': 3, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 3, 'penalty': 'l2'}\n",
      "0.780 (+/-0.013) for {'C': 4, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 4, 'penalty': 'l2'}\n",
      "0.780 (+/-0.013) for {'C': 5, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 5, 'penalty': 'l2'}\n",
      "0.780 (+/-0.013) for {'C': 6, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 6, 'penalty': 'l2'}\n",
      "0.780 (+/-0.013) for {'C': 7, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 7, 'penalty': 'l2'}\n",
      "0.780 (+/-0.013) for {'C': 8, 'penalty': 'l1'}\n",
      "0.757 (+/-0.001) for {'C': 8, 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88      1525\n",
      "           1       0.65      0.21      0.32       465\n",
      "\n",
      "    accuracy                           0.79      1990\n",
      "   macro avg       0.72      0.59      0.60      1990\n",
      "weighted avg       0.77      0.79      0.75      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for balanced_accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 2, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "0.500 (+/-0.000) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "0.500 (+/-0.000) for {'C': 0.001, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 0.001, 'penalty': 'l2'}\n",
      "0.506 (+/-0.007) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.558 (+/-0.024) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.572 (+/-0.018) for {'C': 1.0, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 1.0, 'penalty': 'l2'}\n",
      "0.577 (+/-0.011) for {'C': 2, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 2, 'penalty': 'l2'}\n",
      "0.575 (+/-0.023) for {'C': 3, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 3, 'penalty': 'l2'}\n",
      "0.575 (+/-0.023) for {'C': 4, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 4, 'penalty': 'l2'}\n",
      "0.575 (+/-0.023) for {'C': 5, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 5, 'penalty': 'l2'}\n",
      "0.575 (+/-0.023) for {'C': 6, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 6, 'penalty': 'l2'}\n",
      "0.575 (+/-0.023) for {'C': 7, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 7, 'penalty': 'l2'}\n",
      "0.575 (+/-0.023) for {'C': 8, 'penalty': 'l1'}\n",
      "0.500 (+/-0.000) for {'C': 8, 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88      1525\n",
      "           1       0.66      0.21      0.32       465\n",
      "\n",
      "    accuracy                           0.79      1990\n",
      "   macro avg       0.73      0.59      0.60      1990\n",
      "weighted avg       0.77      0.79      0.75      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "Best parameters set found on development set:\n",
      "{'C': 2, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.000 (+/-0.000) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "0.000 (+/-0.000) for {'C': 0.001, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 0.001, 'penalty': 'l2'}\n",
      "0.026 (+/-0.028) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.227 (+/-0.076) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.274 (+/-0.059) for {'C': 1.0, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 1.0, 'penalty': 'l2'}\n",
      "0.287 (+/-0.032) for {'C': 2, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 2, 'penalty': 'l2'}\n",
      "0.281 (+/-0.062) for {'C': 3, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 3, 'penalty': 'l2'}\n",
      "0.280 (+/-0.063) for {'C': 4, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 4, 'penalty': 'l2'}\n",
      "0.280 (+/-0.063) for {'C': 5, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 5, 'penalty': 'l2'}\n",
      "0.280 (+/-0.063) for {'C': 6, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 6, 'penalty': 'l2'}\n",
      "0.280 (+/-0.063) for {'C': 7, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 7, 'penalty': 'l2'}\n",
      "0.280 (+/-0.063) for {'C': 8, 'penalty': 'l1'}\n",
      "0.000 (+/-0.000) for {'C': 8, 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88      1525\n",
      "           1       0.66      0.21      0.32       465\n",
      "\n",
      "    accuracy                           0.79      1990\n",
      "   macro avg       0.73      0.59      0.60      1990\n",
      "weighted avg       0.77      0.79      0.75      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "Best parameters set found on development set:\n",
      "{'C': 2, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.567 (+/-0.035) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "0.604 (+/-0.045) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "0.589 (+/-0.041) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "0.626 (+/-0.047) for {'C': 0.001, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 0.001, 'penalty': 'l2'}\n",
      "0.677 (+/-0.023) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.725 (+/-0.016) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.728 (+/-0.008) for {'C': 1.0, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 1.0, 'penalty': 'l2'}\n",
      "0.730 (+/-0.015) for {'C': 2, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 2, 'penalty': 'l2'}\n",
      "0.729 (+/-0.016) for {'C': 3, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 3, 'penalty': 'l2'}\n",
      "0.729 (+/-0.016) for {'C': 4, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 4, 'penalty': 'l2'}\n",
      "0.729 (+/-0.016) for {'C': 5, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 5, 'penalty': 'l2'}\n",
      "0.729 (+/-0.016) for {'C': 6, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 6, 'penalty': 'l2'}\n",
      "0.729 (+/-0.016) for {'C': 7, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 7, 'penalty': 'l2'}\n",
      "0.729 (+/-0.016) for {'C': 8, 'penalty': 'l1'}\n",
      "0.602 (+/-0.045) for {'C': 8, 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88      1525\n",
      "           1       0.66      0.21      0.32       465\n",
      "\n",
      "    accuracy                           0.79      1990\n",
      "   macro avg       0.73      0.59      0.60      1990\n",
      "weighted avg       0.77      0.79      0.75      1990\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the grid search on logistic regression\n",
    "parameters = [{'penalty': ['l1', 'l2'],\n",
    "               'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 2, 3, 4, 5, 6, 7, 8]}]\n",
    "# Evaluation metrics\n",
    "scores = {\"accuracy\": \"accuracy\", \"balanced_accuracy\": \"balanced_accuracy\", \"f1\": \"f1\", \"roc_auc\": \"roc_auc\"}\n",
    "\n",
    "# Create a dictionary to store the grid search results\n",
    "records_lr = dict()\n",
    "\n",
    "# Loop through the evaluation metrics\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    #Construct a grid search object with 5-fold cross validation\n",
    "    clf = GridSearchCV(LogisticRegression(random_state=seed, solver='liblinear',\n",
    "                                          max_iter=1000),\n",
    "                       parameters, cv=5, scoring=score, n_jobs=-1)\n",
    "    #Doing 5-fold cross validation on the training set\n",
    "    clf.fit(X_train, np.ravel(y_train))\n",
    "    #Print the best parameters and the corresponding score\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    records_lr[score] = clf\n",
    "\n",
    "    # List all performance of all parameters combination\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_val, clf.predict(X_val)\n",
    "\n",
    "    # Print the classification report based on the best parameters\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "poly1 = PolynomialFeatures(interaction_only=True)\n",
    "X_train_d2 = poly1.fit_transform(X_train)\n",
    "X_val_d2 = poly1.transform(X_val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.1, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.763 (+/-0.007) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "0.762 (+/-0.008) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "0.763 (+/-0.008) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "0.762 (+/-0.008) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "0.771 (+/-0.007) for {'C': 0.001, 'penalty': 'l1'}\n",
      "0.763 (+/-0.007) for {'C': 0.001, 'penalty': 'l2'}\n",
      "0.779 (+/-0.010) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.762 (+/-0.007) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.784 (+/-0.022) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.762 (+/-0.007) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.781 (+/-0.016) for {'C': 1.0, 'penalty': 'l1'}\n",
      "0.762 (+/-0.008) for {'C': 1.0, 'penalty': 'l2'}\n",
      "0.780 (+/-0.013) for {'C': 2, 'penalty': 'l1'}\n",
      "0.763 (+/-0.007) for {'C': 2, 'penalty': 'l2'}\n",
      "0.779 (+/-0.010) for {'C': 3, 'penalty': 'l1'}\n",
      "0.762 (+/-0.008) for {'C': 3, 'penalty': 'l2'}\n",
      "0.779 (+/-0.010) for {'C': 4, 'penalty': 'l1'}\n",
      "0.762 (+/-0.008) for {'C': 4, 'penalty': 'l2'}\n",
      "0.779 (+/-0.009) for {'C': 5, 'penalty': 'l1'}\n",
      "0.762 (+/-0.008) for {'C': 5, 'penalty': 'l2'}\n",
      "0.780 (+/-0.008) for {'C': 6, 'penalty': 'l1'}\n",
      "0.762 (+/-0.007) for {'C': 6, 'penalty': 'l2'}\n",
      "0.780 (+/-0.009) for {'C': 7, 'penalty': 'l1'}\n",
      "0.762 (+/-0.008) for {'C': 7, 'penalty': 'l2'}\n",
      "0.780 (+/-0.010) for {'C': 8, 'penalty': 'l1'}\n",
      "0.762 (+/-0.007) for {'C': 8, 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.87      1525\n",
      "           1       0.55      0.22      0.32       465\n",
      "\n",
      "    accuracy                           0.78      1990\n",
      "   macro avg       0.67      0.58      0.59      1990\n",
      "weighted avg       0.74      0.78      0.74      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for balanced_accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 2, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.522 (+/-0.011) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "0.523 (+/-0.013) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "0.522 (+/-0.014) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "0.523 (+/-0.013) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "0.550 (+/-0.015) for {'C': 0.001, 'penalty': 'l1'}\n",
      "0.524 (+/-0.013) for {'C': 0.001, 'penalty': 'l2'}\n",
      "0.585 (+/-0.021) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.522 (+/-0.012) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.604 (+/-0.031) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.523 (+/-0.012) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.605 (+/-0.026) for {'C': 1.0, 'penalty': 'l1'}\n",
      "0.523 (+/-0.013) for {'C': 1.0, 'penalty': 'l2'}\n",
      "0.606 (+/-0.024) for {'C': 2, 'penalty': 'l1'}\n",
      "0.523 (+/-0.013) for {'C': 2, 'penalty': 'l2'}\n",
      "0.604 (+/-0.021) for {'C': 3, 'penalty': 'l1'}\n",
      "0.523 (+/-0.014) for {'C': 3, 'penalty': 'l2'}\n",
      "0.604 (+/-0.022) for {'C': 4, 'penalty': 'l1'}\n",
      "0.523 (+/-0.013) for {'C': 4, 'penalty': 'l2'}\n",
      "0.605 (+/-0.020) for {'C': 5, 'penalty': 'l1'}\n",
      "0.523 (+/-0.013) for {'C': 5, 'penalty': 'l2'}\n",
      "0.605 (+/-0.019) for {'C': 6, 'penalty': 'l1'}\n",
      "0.522 (+/-0.011) for {'C': 6, 'penalty': 'l2'}\n",
      "0.606 (+/-0.019) for {'C': 7, 'penalty': 'l1'}\n",
      "0.523 (+/-0.013) for {'C': 7, 'penalty': 'l2'}\n",
      "0.606 (+/-0.019) for {'C': 8, 'penalty': 'l1'}\n",
      "0.522 (+/-0.012) for {'C': 8, 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      1525\n",
      "           1       0.51      0.23      0.32       465\n",
      "\n",
      "    accuracy                           0.77      1990\n",
      "   macro avg       0.66      0.58      0.59      1990\n",
      "weighted avg       0.73      0.77      0.73      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "Best parameters set found on development set:\n",
      "{'C': 2, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.100 (+/-0.037) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "0.103 (+/-0.043) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "0.101 (+/-0.046) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "0.103 (+/-0.043) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "0.202 (+/-0.048) for {'C': 0.001, 'penalty': 'l1'}\n",
      "0.108 (+/-0.043) for {'C': 0.001, 'penalty': 'l2'}\n",
      "0.314 (+/-0.054) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.102 (+/-0.040) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.364 (+/-0.069) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.104 (+/-0.040) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.368 (+/-0.060) for {'C': 1.0, 'penalty': 'l1'}\n",
      "0.103 (+/-0.043) for {'C': 1.0, 'penalty': 'l2'}\n",
      "0.371 (+/-0.055) for {'C': 2, 'penalty': 'l1'}\n",
      "0.107 (+/-0.044) for {'C': 2, 'penalty': 'l2'}\n",
      "0.367 (+/-0.049) for {'C': 3, 'penalty': 'l1'}\n",
      "0.105 (+/-0.046) for {'C': 3, 'penalty': 'l2'}\n",
      "0.367 (+/-0.052) for {'C': 4, 'penalty': 'l1'}\n",
      "0.103 (+/-0.043) for {'C': 4, 'penalty': 'l2'}\n",
      "0.368 (+/-0.048) for {'C': 5, 'penalty': 'l1'}\n",
      "0.103 (+/-0.043) for {'C': 5, 'penalty': 'l2'}\n",
      "0.370 (+/-0.044) for {'C': 6, 'penalty': 'l1'}\n",
      "0.102 (+/-0.038) for {'C': 6, 'penalty': 'l2'}\n",
      "0.370 (+/-0.044) for {'C': 7, 'penalty': 'l1'}\n",
      "0.103 (+/-0.043) for {'C': 7, 'penalty': 'l2'}\n",
      "0.371 (+/-0.045) for {'C': 8, 'penalty': 'l1'}\n",
      "0.101 (+/-0.038) for {'C': 8, 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.93      0.86      1525\n",
      "           1       0.51      0.23      0.32       465\n",
      "\n",
      "    accuracy                           0.77      1990\n",
      "   macro avg       0.66      0.58      0.59      1990\n",
      "weighted avg       0.73      0.77      0.73      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.01, 'penalty': 'l1'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.688 (+/-0.027) for {'C': 1e-05, 'penalty': 'l1'}\n",
      "0.694 (+/-0.027) for {'C': 1e-05, 'penalty': 'l2'}\n",
      "0.701 (+/-0.022) for {'C': 0.0001, 'penalty': 'l1'}\n",
      "0.694 (+/-0.025) for {'C': 0.0001, 'penalty': 'l2'}\n",
      "0.722 (+/-0.020) for {'C': 0.001, 'penalty': 'l1'}\n",
      "0.695 (+/-0.027) for {'C': 0.001, 'penalty': 'l2'}\n",
      "0.733 (+/-0.024) for {'C': 0.01, 'penalty': 'l1'}\n",
      "0.693 (+/-0.026) for {'C': 0.01, 'penalty': 'l2'}\n",
      "0.731 (+/-0.031) for {'C': 0.1, 'penalty': 'l1'}\n",
      "0.694 (+/-0.027) for {'C': 0.1, 'penalty': 'l2'}\n",
      "0.721 (+/-0.031) for {'C': 1.0, 'penalty': 'l1'}\n",
      "0.693 (+/-0.025) for {'C': 1.0, 'penalty': 'l2'}\n",
      "0.719 (+/-0.031) for {'C': 2, 'penalty': 'l1'}\n",
      "0.698 (+/-0.028) for {'C': 2, 'penalty': 'l2'}\n",
      "0.719 (+/-0.030) for {'C': 3, 'penalty': 'l1'}\n",
      "0.694 (+/-0.025) for {'C': 3, 'penalty': 'l2'}\n",
      "0.718 (+/-0.030) for {'C': 4, 'penalty': 'l1'}\n",
      "0.694 (+/-0.026) for {'C': 4, 'penalty': 'l2'}\n",
      "0.718 (+/-0.030) for {'C': 5, 'penalty': 'l1'}\n",
      "0.694 (+/-0.026) for {'C': 5, 'penalty': 'l2'}\n",
      "0.718 (+/-0.030) for {'C': 6, 'penalty': 'l1'}\n",
      "0.694 (+/-0.025) for {'C': 6, 'penalty': 'l2'}\n",
      "0.718 (+/-0.030) for {'C': 7, 'penalty': 'l1'}\n",
      "0.693 (+/-0.025) for {'C': 7, 'penalty': 'l2'}\n",
      "0.718 (+/-0.032) for {'C': 8, 'penalty': 'l1'}\n",
      "0.695 (+/-0.030) for {'C': 8, 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.96      0.87      1525\n",
      "           1       0.62      0.21      0.31       465\n",
      "\n",
      "    accuracy                           0.79      1990\n",
      "   macro avg       0.71      0.59      0.59      1990\n",
      "weighted avg       0.76      0.79      0.74      1990\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the grid search on logistic regression\n",
    "parameters = [{'penalty': ['l1', 'l2'],\n",
    "               'C': [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 2, 3, 4, 5, 6, 7, 8]}]\n",
    "# Evaluation metrics\n",
    "scores = {\"accuracy\": \"accuracy\", \"balanced_accuracy\": \"balanced_accuracy\", \"f1\": \"f1\", \"roc_auc\": \"roc_auc\"}\n",
    "\n",
    "# Create a dictionary to store the grid search results\n",
    "records_kernel_lr = dict()\n",
    "\n",
    "# Loop through the evaluation metrics\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    #Construct a grid search object with 5-fold cross validation\n",
    "    clf = GridSearchCV(LogisticRegression(random_state=seed, solver='liblinear',\n",
    "                                          max_iter=1000),\n",
    "                       parameters, cv=5, scoring=score, n_jobs=-1)\n",
    "    #Doing 5-fold cross validation on the training set\n",
    "    clf.fit(X_train_d2, np.ravel(y_train))\n",
    "    #Print the best parameters and the corresponding score\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    records_kernel_lr[score] = clf\n",
    "\n",
    "    # List all performance of all parameters combination\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_val, clf.predict(X_val_d2)\n",
    "\n",
    "    # Print the classification report based on the best parameters\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.762 (+/-0.002) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.502 (+/-0.364) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.748 (+/-0.070) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.616 (+/-0.378) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.566 (+/-0.388) for {'C': 1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.652 (+/-0.176) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.721 (+/-0.086) for {'C': 5, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.676 (+/-0.186) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.720 (+/-0.087) for {'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.722 (+/-0.085) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.748 (+/-0.050) for {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.721 (+/-0.087) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1525\n",
      "           1       0.70      0.03      0.07       465\n",
      "\n",
      "    accuracy                           0.77      1990\n",
      "   macro avg       0.73      0.51      0.47      1990\n",
      "weighted avg       0.75      0.77      0.68      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for balanced_accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.515 (+/-0.008) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.547 (+/-0.020) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.577 (+/-0.094) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.578 (+/-0.075) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.547 (+/-0.069) for {'C': 1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.591 (+/-0.039) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.578 (+/-0.034) for {'C': 5, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.524 (+/-0.045) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.577 (+/-0.035) for {'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.580 (+/-0.037) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.550 (+/-0.075) for {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.578 (+/-0.036) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      1525\n",
      "           1       0.32      0.35      0.33       465\n",
      "\n",
      "    accuracy                           0.67      1990\n",
      "   macro avg       0.56      0.56      0.56      1990\n",
      "weighted avg       0.68      0.67      0.68      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.069 (+/-0.036) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.343 (+/-0.181) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.274 (+/-0.282) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.353 (+/-0.214) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.342 (+/-0.110) for {'C': 1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.396 (+/-0.032) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.338 (+/-0.079) for {'C': 5, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.222 (+/-0.220) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.337 (+/-0.079) for {'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.342 (+/-0.079) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.224 (+/-0.266) for {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.338 (+/-0.078) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.78      1525\n",
      "           1       0.32      0.35      0.33       465\n",
      "\n",
      "    accuracy                           0.67      1990\n",
      "   macro avg       0.56      0.56      0.56      1990\n",
      "weighted avg       0.68      0.67      0.68      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.668 (+/-0.025) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.569 (+/-0.088) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.685 (+/-0.030) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.638 (+/-0.094) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.593 (+/-0.200) for {'C': 1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.642 (+/-0.081) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.646 (+/-0.080) for {'C': 5, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.583 (+/-0.085) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.645 (+/-0.080) for {'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.646 (+/-0.079) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.657 (+/-0.075) for {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.645 (+/-0.080) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.12      0.20      1525\n",
      "           1       0.24      0.91      0.38       465\n",
      "\n",
      "    accuracy                           0.30      1990\n",
      "   macro avg       0.52      0.51      0.29      1990\n",
      "weighted avg       0.67      0.30      0.24      1990\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the grid search on logistic regression\n",
    "parameters = [{'penalty': ['l1', 'l2'],\n",
    "               'C': [1e-2, 1e-1, 1, 5, 10, 100],\n",
    "               'class_weight': [None, 'balanced'],\n",
    "               }]\n",
    "# Evaluation metrics\n",
    "scores = {\"accuracy\": \"accuracy\", \"balanced_accuracy\": \"balanced_accuracy\", \"f1\": \"f1\", \"roc_auc\": \"roc_auc\"}\n",
    "\n",
    "# Create a dictionary to store the grid search results\n",
    "records_svm = dict()\n",
    "\n",
    "# Loop through the evaluation metrics\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    #Construct a grid search object with 5-fold cross validation\n",
    "    clf = GridSearchCV(LinearSVC(loss='squared_hinge', random_state=seed),\n",
    "                       parameters, cv=3, scoring=score, n_jobs=-1)\n",
    "    #Doing 5-fold cross validation on the training set\n",
    "    clf.fit(X_train, np.ravel(y_train))\n",
    "    #Print the best parameters and the corresponding score\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    records_svm[score] = clf\n",
    "\n",
    "    # List all performance of all parameters combination\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_val, clf.predict(X_val)\n",
    "\n",
    "    # Print the classification report based on the best parameters\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.714 (+/-0.093) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.437 (+/-0.324) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.564 (+/-0.332) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.564 (+/-0.331) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.564 (+/-0.331) for {'C': 1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.565 (+/-0.331) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.564 (+/-0.331) for {'C': 5, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.565 (+/-0.331) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.564 (+/-0.331) for {'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.564 (+/-0.331) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.564 (+/-0.331) for {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.564 (+/-0.331) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.25      0.39      1525\n",
      "           1       0.26      0.85      0.39       465\n",
      "\n",
      "    accuracy                           0.39      1990\n",
      "   macro avg       0.55      0.55      0.39      1990\n",
      "weighted avg       0.70      0.39      0.39      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for balanced_accuracy\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.518 (+/-0.021) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.522 (+/-0.010) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.503 (+/-0.050) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.503 (+/-0.051) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.503 (+/-0.050) for {'C': 1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.503 (+/-0.051) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.503 (+/-0.050) for {'C': 5, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.503 (+/-0.051) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.503 (+/-0.050) for {'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.503 (+/-0.050) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.503 (+/-0.050) for {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.503 (+/-0.050) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.33      0.46      1525\n",
      "           1       0.25      0.73      0.37       465\n",
      "\n",
      "    accuracy                           0.42      1990\n",
      "   macro avg       0.52      0.53      0.42      1990\n",
      "weighted avg       0.67      0.42      0.44      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.159 (+/-0.196) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.352 (+/-0.118) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.240 (+/-0.220) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 5, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.240 (+/-0.221) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.33      0.46      1525\n",
      "           1       0.25      0.73      0.37       465\n",
      "\n",
      "    accuracy                           0.42      1990\n",
      "   macro avg       0.52      0.53      0.42      1990\n",
      "weighted avg       0.67      0.42      0.44      1990\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "Best parameters set found on development set:\n",
      "{'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "Grid scores on development set:\n",
      "\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.584 (+/-0.023) for {'C': 0.01, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.500 (+/-0.101) for {'C': 0.01, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 0.1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 0.1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 1, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 5, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 5, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 10, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 10, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': None, 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 100, 'class_weight': None, 'penalty': 'l2'}\n",
      "nan (+/-nan) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l1'}\n",
      "0.526 (+/-0.086) for {'C': 100, 'class_weight': 'balanced', 'penalty': 'l2'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.25      0.39      1525\n",
      "           1       0.26      0.85      0.39       465\n",
      "\n",
      "    accuracy                           0.39      1990\n",
      "   macro avg       0.55      0.55      0.39      1990\n",
      "weighted avg       0.70      0.39      0.39      1990\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'penalty': ['l1', 'l2'],\n",
    "               'C': [1e-2, 1e-1, 1, 5, 10, 100],\n",
    "               'class_weight': [None, 'balanced'],\n",
    "               }]\n",
    "# Evaluation metrics\n",
    "scores = {\"accuracy\": \"accuracy\", \"balanced_accuracy\": \"balanced_accuracy\", \"f1\": \"f1\", \"roc_auc\": \"roc_auc\"}\n",
    "\n",
    "# Create a dictionary to store the grid search results\n",
    "records_kernel_svm = dict()\n",
    "\n",
    "# Loop through the evaluation metrics\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    #Construct a grid search object with 5-fold cross validation\n",
    "    clf = GridSearchCV(LinearSVC(loss='squared_hinge', random_state=seed),\n",
    "                       parameters, cv=3, scoring=score, n_jobs=-1)\n",
    "    #Doing 5-fold cross validation on the training set\n",
    "    clf.fit(X_train_d2, np.ravel(y_train))\n",
    "    #Print the best parameters and the corresponding score\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    records_kernel_svm[score] = clf\n",
    "\n",
    "    # List all performance of all parameters combination\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_val, clf.predict(X_val_d2)\n",
    "\n",
    "    # Print the classification report based on the best parameters\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fuzzy SVM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from scipy.sparse import issparse\n",
    "from scipy.optimize import minimize\n",
    "from numpy.random import RandomState\n",
    "from itertools import product\n",
    "from scipy.optimize import LinearConstraint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class FuzzySVM(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, C=1, kernel='linear', degree=3, coef0=0, gamma=1,\n",
    "                 max_samples=100, tol=None, max_iter=10, random_state=None, disp=False):\n",
    "        self.C = C\n",
    "        self.kernel = kernel\n",
    "        self.degree = degree\n",
    "        self.coef0 = coef0\n",
    "        self.gamma = gamma\n",
    "        self.max_samples = max_samples\n",
    "        self.tol = tol\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "        self.disp = disp\n",
    "\n",
    "        self.kernel_fun = self._get_kernel_fun_by_name(kernel)\n",
    "        self.rs = RandomState(random_state)\n",
    "\n",
    "        self.alphas = None\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.b = None\n",
    "\n",
    "    def fit(self, X, ys):\n",
    "        y = ys\n",
    "        s = [random.random() for y in ys]\n",
    "\n",
    "        # replaces 0 labels with -1\n",
    "        y = y.flatten()\n",
    "        y = np.copy(y)\n",
    "        y[y == 0] = -1\n",
    "\n",
    "        # convert to dense array\n",
    "        if issparse(X):\n",
    "            X = X.A\n",
    "\n",
    "        # sample data\n",
    "        X, y = self._sample_xy(X, y)\n",
    "\n",
    "        # minimization\n",
    "        initial_alphas = np.repeat(0, X.shape[0])\n",
    "        alphas_bounds = [(0, s[i] * self.C) for i in range(X.shape[0])]\n",
    "        constraint1 = LinearConstraint(y, 0, 0)\n",
    "        res = minimize(\n",
    "            self._loss,\n",
    "            initial_alphas,\n",
    "            method='trust-constr',\n",
    "            args=(X, y, self.kernel_fun),\n",
    "            bounds=alphas_bounds,\n",
    "            constraints=(constraint1,),\n",
    "            tol=self.tol,\n",
    "            options={'maxiter': self.max_iter, 'disp': self.disp}\n",
    "        )\n",
    "        alphas = res.x.ravel()\n",
    "\n",
    "        # save results\n",
    "        self.alphas = alphas\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.b = self._calc_bias(alphas, y, X, self.kernel_fun)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def _sample_xy(self, X, y):\n",
    "        n_samples = min(X.shape[0], self.max_samples)\n",
    "        sampled_X, _, sampled_y, _ = train_test_split(\n",
    "            X, y,\n",
    "            train_size=n_samples,\n",
    "            stratify=y,\n",
    "            random_state=self.rs\n",
    "        )\n",
    "        return sampled_X, sampled_y\n",
    "\n",
    "    @staticmethod\n",
    "    def _loss(v, X, ys, kernel_fun):\n",
    "        alphas = v.flatten()\n",
    "        n = alphas.size\n",
    "\n",
    "        s = 0\n",
    "        for i, j in product(range(n), range(n)):\n",
    "            s += alphas[i] * alphas[j] * ys[i] * ys[j] * kernel_fun(X[i], X[j])\n",
    "        return 0.5 * s - np.sum(alphas)\n",
    "\n",
    "    @staticmethod\n",
    "    def _calc_bias(alphas, ys, xs, kernel):\n",
    "        n = xs.shape[0]\n",
    "        outer_sum = 0\n",
    "        for i in range(n):\n",
    "            inner_sum_parts_generator = (alphas[j] * ys[j] * kernel(xs[i], xs[j]) for j in range(n))\n",
    "            inner_sum = sum(inner_sum_parts_generator)\n",
    "            outer_sum_part = ys[i] - inner_sum\n",
    "            outer_sum += outer_sum_part\n",
    "        return outer_sum / n\n",
    "\n",
    "    def _get_kernel_fun_by_name(self, kernel_name):\n",
    "        if kernel_name == 'linear':\n",
    "            return self._kernel_linear\n",
    "        elif kernel_name == 'poly':\n",
    "            return self._kernel_poly\n",
    "        elif kernel_name == 'rbf':\n",
    "            return self._kernel_rbf\n",
    "\n",
    "    def _kernel_linear(self, a, b):\n",
    "        return a @ b\n",
    "\n",
    "    def _kernel_poly(self, a, b):\n",
    "        return (a @ b + self.coef0) ** self.degree\n",
    "\n",
    "    def _kernel_rbf(self, a, b):\n",
    "        diff = a - b\n",
    "        magnitude = np.sqrt(diff @ diff)\n",
    "        return np.exp(-self.gamma * magnitude)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        n = self.X.shape[0]\n",
    "        kernel_fun = np.vectorize(self.kernel_fun, signature='(n),(n)->()')\n",
    "        sum_parts = (self.alphas[i] * self.y[i] * kernel_fun(self.X[i], X) for i in range(n))\n",
    "        sum_value = sum(sum_parts)\n",
    "        result = sum_value + self.b\n",
    "        return result.ravel()\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.decision_function(X) > 0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for balanced_accuracy\n",
      "The maximum number of function evaluations is exceeded.\n",
      "Number of iterations: 20, function evaluations: 1717, CG iterations: 89, optimality: 2.18e-03, constraint violation: 3.55e-15, execution time: 8.4e+01 s.\n",
      "Best parameters set found on development set:\n",
      "{'C': 50, 'kernel': 'rbf'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.500 (+/-0.000) for {'C': 0.0001, 'kernel': 'linear'}\n",
      "0.500 (+/-0.000) for {'C': 0.0001, 'kernel': 'rbf'}\n",
      "0.500 (+/-0.000) for {'C': 0.02, 'kernel': 'linear'}\n",
      "0.500 (+/-0.000) for {'C': 0.02, 'kernel': 'rbf'}\n",
      "0.543 (+/-0.059) for {'C': 1, 'kernel': 'linear'}\n",
      "0.548 (+/-0.037) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.561 (+/-0.057) for {'C': 50, 'kernel': 'linear'}\n",
      "0.593 (+/-0.076) for {'C': 50, 'kernel': 'rbf'}\n",
      "0.546 (+/-0.039) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.576 (+/-0.040) for {'C': 1000, 'kernel': 'rbf'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.97      0.86      1525\n",
      "           1       0.26      0.04      0.06       465\n",
      "\n",
      "    accuracy                           0.75      1990\n",
      "   macro avg       0.51      0.50      0.46      1990\n",
      "weighted avg       0.65      0.75      0.67      1990\n",
      "\n",
      "# Tuning hyper-parameters for roc_auc\n",
      "The maximum number of function evaluations is exceeded.\n",
      "Number of iterations: 20, function evaluations: 1616, CG iterations: 65, optimality: 1.47e-04, constraint violation: 1.78e-15, execution time: 7.9e+01 s.\n",
      "Best parameters set found on development set:\n",
      "{'C': 1, 'kernel': 'rbf'}\n",
      "Grid scores on development set:\n",
      "\n",
      "0.578 (+/-0.083) for {'C': 0.0001, 'kernel': 'linear'}\n",
      "0.555 (+/-0.050) for {'C': 0.0001, 'kernel': 'rbf'}\n",
      "0.599 (+/-0.068) for {'C': 0.02, 'kernel': 'linear'}\n",
      "0.597 (+/-0.060) for {'C': 0.02, 'kernel': 'rbf'}\n",
      "0.605 (+/-0.069) for {'C': 1, 'kernel': 'linear'}\n",
      "0.625 (+/-0.048) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.605 (+/-0.087) for {'C': 50, 'kernel': 'linear'}\n",
      "0.579 (+/-0.059) for {'C': 50, 'kernel': 'rbf'}\n",
      "0.586 (+/-0.093) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.562 (+/-0.112) for {'C': 1000, 'kernel': 'rbf'}\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87      1525\n",
      "           1       0.67      0.00      0.01       465\n",
      "\n",
      "    accuracy                           0.77      1990\n",
      "   macro avg       0.72      0.50      0.44      1990\n",
      "weighted avg       0.74      0.77      0.67      1990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = [{'kernel': ['linear', 'rbf'],\n",
    "               'C': [1e-4, 0.02, 1, 50, 1000]\n",
    "               }]\n",
    "# Evaluation metrics\n",
    "scores = {\"balanced_accuracy\": \"balanced_accuracy\",\"roc_auc\": \"roc_auc\"}\n",
    "\n",
    "# Create a dictionary to store the grid search results\n",
    "records_fuzzy_svm = dict()\n",
    "\n",
    "mmc = MinMaxScaler().fit(np.array(X_train))\n",
    "\n",
    "# Loop through the evaluation metrics\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "\n",
    "    #Construct a grid search object with 5-fold cross validation\n",
    "    clf = GridSearchCV(\n",
    "        FuzzySVM(degree=2, max_samples=100, max_iter=20, coef0=1, tol=1e-20, disp=True), param_grid=parameters,\n",
    "        scoring=score, n_jobs=-1,\n",
    "        cv=None)\n",
    "    #Doing 5-fold cross validation on the training set\n",
    "    X_train_m, y_train_m = mmc.transform(np.array(X_train)), np.array(y_train)\n",
    "    clf.fit(X_train_m, y_train_m)\n",
    "    #Print the best parameters and the corresponding score\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "    records_fuzzy_svm[score] = clf\n",
    "\n",
    "    # List all performance of all parameters combination\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    X_val_m, y_val_m = mmc.transform(np.array(X_val)), np.array(y_val)\n",
    "    y_true, y_pred = y_val_m, clf.predict(X_val_m)\n",
    "\n",
    "    # Print the classification report based on the best parameters\n",
    "    print(classification_report(y_true, y_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum number of function evaluations is exceeded.\n",
      "Number of iterations: 100, function evaluations: 20100, CG iterations: 9596, optimality: 6.83e-01, constraint violation: 1.42e-14, execution time: 2e+03 s.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.76      0.79      1525\n",
      "           1       0.38      0.49      0.43       465\n",
      "\n",
      "    accuracy                           0.69      1990\n",
      "   macro avg       0.60      0.62      0.61      1990\n",
      "weighted avg       0.72      0.69      0.71      1990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fuzzy_svm = make_pipeline(\n",
    "    MinMaxScaler(),\n",
    "    FuzzySVM(kernel='linear', degree=2, coef0=1, C=50, max_samples=200, max_iter=100, tol=1e-20, disp=True)\n",
    ")\n",
    "fuzzy_svm.fit(np.array(X_train), np.array(y_train))\n",
    "pickle.dump(fuzzy_svm, open('./fuzzy_svm.md', 'wb'))\n",
    "y_pred = fuzzy_svm.predict(np.array(X_val))\n",
    "print(classification_report(y_val, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "fs_new = pickle.load(open('./fuzzy_svm.md', 'rb'))\n",
    "roc_auc_score(y_val,fs_new[1].predict(fs_new[0].transform(np.array(X_val))))\n",
    "x,y,_=roc_curve(y_val,fs_new[1].predict(fs_new[0].transform(np.array(X_val))))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MACS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5febda9ea3b33ffdc95c888fff59ec7615aa10294cac48f80c25517e6a63b54a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}